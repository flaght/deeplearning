{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Swiss army knife function to organize the data\n",
    "\n",
    "# 提取label，并编码成数字\n",
    "def encode(train, test):\n",
    "    le = LabelEncoder().fit(train.species) \n",
    "    labels = le.transform(train.species)           # encode species strings\n",
    "    classes = list(le.classes_)                    # save column names for submission\n",
    "    test_ids = test.id                             # save test ids for submission\n",
    "    \n",
    "    train = train.drop(['species', 'id'], axis=1)  \n",
    "    test = test.drop(['id'], axis=1)\n",
    "    \n",
    "    scaler = StandardScaler().fit(train.values)\n",
    "    train = scaler.transform(train.values)\n",
    "    test = scaler.transform(test.values)\n",
    "    \n",
    "    return train, labels, test, test_ids, classes\n",
    "\n",
    "train, labels, test, test_ids, classes = encode(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在train数据里划分训练测试数据\n",
    "sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n",
    "\n",
    "for train_index, test_index in sss:\n",
    "    X_train, X_test = train[train_index], train[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_trans(x):\n",
    "    output = np.zeros(99)\n",
    "    output[x] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_soft = map(label_trans, y_train)\n",
    "y_train_soft = np.array(y_train_soft)\n",
    "y_test_soft = map(label_trans, y_test)\n",
    "y_test_soft = np.array(y_test_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configuration variables\n",
    "input_vec_size = lstm_size = 64\n",
    "time_step_size = 3\n",
    "train_size = batch_size = 792\n",
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X, W, B, lstm_size):\n",
    "    # X, input shape: (batch_size, time_step_size, input_vec_size)\n",
    "    XT = tf.transpose(X, [1, 0, 2])  # permute time_step_size and batch_size\n",
    "    # XT shape: (time_step_size, batch_size, input_vec_size)\n",
    "    XR = tf.reshape(XT, [-1, lstm_size]) # each row has input for each lstm cell (lstm_size=input_vec_size)\n",
    "    # XR shape: (time_step_size * batch_size, input_vec_size)\n",
    "    X_split = tf.split(0, time_step_size, XR) # split them to time_step_size (28 arrays)\n",
    "    # Each array shape: (batch_size, input_vec_size)\n",
    "\n",
    "    # Make lstm with lstm_size (each input vector size)\n",
    "    lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_size, forget_bias=1.0, state_is_tuple=True)\n",
    "\n",
    "    # Get lstm cell output, time_step_size (28) arrays with lstm_size output: (batch_size, lstm_size)\n",
    "    outputs, _states = tf.nn.rnn(lstm, X_split, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get the last output\n",
    "    return tf.matmul(outputs[-1], W) + B, lstm.state_size # State size to initialize the stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, 3, 64])\n",
    "Y = tf.placeholder(\"float\", [None, 99])\n",
    "\n",
    "# get lstm_size and output 10 labels\n",
    "W = init_weights([lstm_size, 99])\n",
    "B = init_weights([99])\n",
    "\n",
    "py_x, state_size = model(X, W, B, lstm_size)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y))\n",
    "train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "yprob_op = tf.nn.softmax(py_x)\n",
    "predict_op = tf.argmax(py_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,3,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(-1,3,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.reshape(-1,3,64)\n",
    "test = test.reshape(-1,3,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.54273987e-08   1.73387363e-07   9.99206051e-10 ...,   7.59505525e-09\n",
      "    5.60039507e-06   4.52898412e-08]\n",
      " [  1.40732475e-08   5.39953904e-09   3.31432517e-08 ...,   2.48090128e-05\n",
      "    1.17251338e-08   2.22896013e-08]\n",
      " [  2.44738743e-07   9.99342501e-01   1.94365430e-08 ...,   1.31570861e-13\n",
      "    9.93593403e-08   3.20608997e-05]\n",
      " ..., \n",
      " [  5.96643304e-07   3.28673444e-08   1.66487037e-08 ...,   1.09860288e-07\n",
      "    1.73401602e-07   9.04308521e-08]\n",
      " [  2.82783237e-08   4.87330265e-09   2.72585257e-05 ...,   1.20873813e-06\n",
      "    6.75728318e-09   2.92259784e-07]\n",
      " [  1.38224371e-11   7.99293076e-09   3.18882144e-07 ...,   1.21144810e-08\n",
      "    1.69656639e-12   6.82837609e-09]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    for i in range(1000):\n",
    "        sess.run(train_op,feed_dict={X: X_train, Y: y_train_soft})\n",
    "        \n",
    "        #print(i, np.mean(y_test ==\n",
    "                         #sess.run(predict_op, feed_dict={X: X_test})))\n",
    "        \n",
    "    label_soft = map(label_trans, labels)\n",
    "    label_soft = np.array(label_soft)\n",
    "    sess.run(train_op, feed_dict={X:train, Y: label_soft})\n",
    "    yprob = sess.run(yprob_op, feed_dict={X:test})\n",
    "    print(yprob)\n",
    "    submission = pd.DataFrame(yprob, index=test_ids, columns=classes)\n",
    "    submission = submission.reset_index()\n",
    "    submission.to_csv(\"rnn_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [tensor]",
   "language": "python",
   "name": "Python [tensor]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
